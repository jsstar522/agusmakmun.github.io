---
layout: post
title:  "데이터 사이언스 질문 모음 (개인질문 정리)"
date:   2020-09-08 09:02:00 +0900
categories: [deeplearning]
use_math: true
---

## 데이터 사이언스 질문 모음 (개인질문 정리)

```
비지니스를 이해하는 데이터 엔지니어가 되고 싶은 박종석입니다. 석사과정 연구실에서 입자물리 데이터 분석과 generative model을 개발한 경험이 있습니다. 또한 인공지능 연구소에서 데이터 수집 프로젝트를 진행하면서 데이터 분석의 의미와 재미를 알게되었습니다. 이러한 경험들이 카카오 엔터프라이즈의 데이터 마이닝 업무에 적합하다고 생각하고 이 곳에서 가치있는 것들을 이끌어 낼 수 있을 것이라고 생각하여 지원하였습니다. 감사합니다.
```

* 무슨일을 하는 곳인지 아는가?
  * 데이터 분석을 통해 유저의 관심사를 알아내고 추천으로 연결될 수 있도록 하는 서비스
  * 주로 텍스트 데이터를 다루고 이를 통해 유저를 분석. 키워드 추천. 서비스 개인화 연구
  * 실시간 검색어, 관련 검색어, 검색어 자동완성
* 내가 할 수 있는 일
  * 키워드 추출, 검색패턴, 광고
  * 사용자 로그 데이터와 같은 시계열 데이터를 이용해서 관심사 및 이 서비스를 이용하는 이유 등을 분석할 수 있습니다.
  * 제가 연구했던 GAN은 데이터의 확률분포를 근사시키는 것이 주목적으로, 확률분포가 얼마나 비슷한지에 대한 분석이 필요했습니다. 이를 응용하여 사용자의 행동과 관심사 등의 확률분포를 이용하여 사용자의 종류를 나눌 수 있고, 군집화를 시킬 수도 있습니다. 사용자의 종류를 나눌 수 있다는 것은 그에 맞는 서비스나 광고를 더 적은 비용, 효율적으로 제공할 수 있습니다.
* 지원이유
  * 카카오는 계열사가 굉장히 많습니다. 특히 카카오 엔터프라이즈는 B2B 솔루션 및 플랫폼 제작을 목표로 하고 있습니다.
  * 최근 카카오워크 AI 기능 (캐스퍼)
* 하둡과 스파크
  * 연구실 서버가 하둡 파일 시스템이었다.
  * 2학기때 수업을 들었다
* 하둡 파일시스템의 원리에 대해서
  * 하둡은 슈퍼컴퓨터가 아니더라도 여러대의 서버에 데이터를 저장하고, 불러올 때는 저장된 각 서버에서 동시에 데이터를 불러와서 처리할 수 있음.
  * 하트비트, rack, name node
* 하둡의 맵리듀스 방식에 대해서
* 하둡의 쿼리에 대해서
  * hdfs dfs -put "local" "hdfs"
  * yarn

* 프로젝트 (논문)
  * 입자가 검출기에 부딪쳐서 흡수된 에너지 데이터가 기록되는데, 이 이미지를 시뮬레이션하는 모델을 개발했습니다. 원래 Geant4라는 툴킷을 사용했는데 GAN을 이용하여 얼마나 높은 성능과 정확도를 가지고 이 툴킷을 모사할 수 있는지 연구했습니다. 
  * 용량 100만개의 24x24 1.4G
    * Geant4의 이미지 생성 시간이 너무 오래걸림
  * 프로세스
    * Geant4 데이터 수집 - normalization - discriminator 구성 및 output이 0~1로 나오게했다(sigmoid 함수) - generator은 latent space가 layer을 통과한 이후 Geant4 이미지와 같은 크기의 이미지로 만들어지도록 함 - 네트워크 두개를 적대적으로 학습시킴 - loss function은 binary cross entropy를 사용
    * Discriminator 하나를 더 추가함
    * relu은 sigmoid의 변형인데 0보다 작은 수는 0, 0보다 큰 수는 선형으로 값을 갖게하는 함수다. 
    * KLD를 계산하여 real 데이터와 fake 데이터의 확률분포의 차이를 계산
      * $D = - \sum P(x)log(\frac{Q(x)}{P(x)})$
      * 머신러닝에서 cross entropy은 `해당사건이 일어날 확률 x log(해당사건이 일어날 추정확률)` 의 합의 -값입니다.
      * **확률 분포와 그 근사 확률분포 간의 차이를 계산하는 것**
* ROOT가 무엇인가?
  * 입자물리학에서 사용하는 빅데이터 분석 프레임워크. 데이터 저장, 분석, 그리기 모두 할 수 있다. C++ 기반

* 프로젝트 (유튜브)
* 프로젝트 (스타트업)
  * 관계형 DB vs 비관계형 DB
* 파이썬 기본질문
  * 
* 가장 최근에 본 논문
  * GPT-3
  * Autoregressive model
  * 다음에 올 단어를 계속 이어서 학습한다. (자기회귀)
  * GPT-3은 `zero shot`, `one shot`, `few shot` 중 few shot learning이 핵심이다. 데이터가 많다고 좋은 것은 아니다. 인간은 몇개의 데이터만 가지고 학습을 할 수 있다. 이러한 점을 기계도 할 수 있는지 학습시키는 것이 few shot learning이고 GPT-3가 증명했다.
* Softmax layer의 연산이 무거워 다른 방법으로 대체하려고 하는데 어떤 방법이 고려될 수 있는가?
  * Softmax = $\frac{e^{x_i}}{\sum_k e^{x_k}}$
  * Softmax을 사용하지 않고 가장 큰 값을 1, 나머지를 0으로 바꾸는 방법이 있다. 혹은 normalization을 해서 출력하는 방법이 있다. 
  * 다만 softmax은 지수함수이기 때문에 입력값의 차이가 크면 클수록 값의 차이가 dramatic하게 변하기 때문에 실제 target과 비슷한 예측값이 나왔을 때 loss를 최소화시킬 수 있습니다. 또한 음의 수를 예방할 수 있습니다.
* GAN이 학습되지 않을 때 어떤 것을 먼저 고려해 보았는가?
  * Discriminator나 Generator의 학습이 비정상적으로 편향되어 이루어지는 것을 고려했습니다.
  * 각 네트워크의 loss를 계속 모니터링 했는데 한쪽 네트워크의 loss가 갑자기 0으로 수렴해버리거나 발산해버리면 이는 학습이 제대로 되지 않는다는 것을 의미합니다.
  * 그래서 각 네트워크의 파라미터 개수를 조정해가면서 조심스럽게 수정했습니다. 저울질 하는 것 처럼요.
* Deep network의 디버깅
  * tensorboard
  * loss 모니터링 (실시간)
* 몬테카를로 방식
  * random number을 이용해서 함수 값을 확률적으로 계산하는 알고리즘
  * 대표적으로 원의 넓이를 구하는 방법이 있는데, (x, y)쌍 random number를 10,000개를 발생시켜 x, y가 $x^2 + y^2 <= 1$ 을 만족하는 random number의 개수를 구하고 전체에 대한 비율을 구하면 원의 넓이를 구할 수 있다.