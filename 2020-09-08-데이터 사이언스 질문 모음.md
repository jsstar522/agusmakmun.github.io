---
layout: post
title:  "데이터 사이언스 질문 모음"
date:   2020-09-08 09:02:00 +0900
categories: [deeplearning]
use_math: true
---

## 데이터 사이언스 질문 모음

이 포스팅은 유명한 <[https://zzsza.github.io/data/2018/02/17/datascience-interivew-questions/#%EC%9E%90%EC%97%B0%EC%96%B4-%EC%B2%98%EB%A6%AC](https://zzsza.github.io/data/2018/02/17/datascience-interivew-questions/#자연어-처리)> 에서 정리해둔 질문 모음에 대한 나의 답변을 최대한 적어두었다. (정확하지 않을 수도 있고 계속 수정해 나아가며 정리할 예정)

### 자연어 처리

* One-hot 인코딩에 대한 설명을 해주세요
  * <https://jsstar522.github.io/deeplearning/2020/09/02/One-hot-encoding.html>
* POS 태깅은 무엇인가요? 가장 간단하게 POS tagger을 만드는 방법은 무엇일까요?
  * POS 태깅은 문장의 품사를 매기는 방식입니다. 품사란 명사, 대명사, 수사, 조사, 동사, 형용사, 관형사, 부사, 감탄사의 9가지로 나뉘는데, 이는 한글 기준이고 영어는 다른 기준을 가지고 있습니다. 그래서 영어와 한글은 형태소 분석을 다르게 해야하는데, 가장 간단하게 만드는 방법은 형태소 분석기를 사용하는 방법입니다. 유명한 `KoNLPy (nltk)` 라이브러리가 있습니다. 이 안에 분석기의 종류에는 꼬꼬마, 코모란, 트위터가 있습니다.
* 문장에서 "Apple"이란 단어가 과일인지 회사인지 식별하는 모델을 어떻게 훈련시킬 수 있을까요?
  * Apple이라는 단어 앞 뒤에 오는 단어를 분석하면 됩니다. '먹다', '깎다' 등의 단어가 오면 과일이고 '스마트폰', '주식'과 같은 단어가 오면 회사입니다. Apple 이라는 단어를 찾아서 앞 뒤에 있는 단어와 함께 학습시키면 과일인지 회사인지 알 수 있는 모델을 훈련시킬 수 있습니다.
* 뉴스 기사에 인용된 텍스트의 모든 항목을 어떻게 찾을 수 있을까요?
* 음성 인식 시스템에서 생성된 텍스트를 자동으로 수정하는 시스템을 어떻게 구축할까요?
  * 문장이 제대로 되었는지 파악하려면 토큰화를 해봐야하는데 토큰화를 하려면 먼저 띄어쓰기가 잘 되어 있어야 합니다. 띄어쓰기를 수정하는 모델이 필요하고 띄어쓰기 수정이 이루어지면 토큰화를 해야합니다. 토큰화를 한 뒤 문장이 자연스러운지 평가해야합니다. 예를 들어 "친구랑 코피를 마셨어"라는 단어는 부자연스럽기 때문에 단어를 바꿔줘야한다는 판단을 내려야 합니다. "코피"와 비슷한 발음이 나는 단어들 중 문맥에 가장 잘 어울리는 단어를 대입시킵니다. 이는 검색창에서 오타를 냈을 때 "~을 검색했나요?"라고 나오는 것 기능과 비슷할 것 같습니다.
* 잠재론적, 의미론적 색인은 무엇이고 어떻게 적용할 수 있을까요?
* 영어 텍스트를 다른 언어로 번역할 시스템을 어떻게 구축해야 할까요?
  * 단어로 구성된 문장 $\to$ 모든 단어 토큰화 및 임베딩 (인코더) $\to$ Network (RNN 기반) $\to$ 디코더 $\to$ 정답 (번역된 말)
  * Attention 기법은 번역문의 특정 단어를 예측할 때 원문에 대응하는 단어의 가중치 정보를 학습하여 활용하는 방식입니다.
  * https://tech.kakaoenterprise.com/22
* 뉴스 기사를 주제별로 자동 분류하는 시스템을 어떻게 구축할까요?
  * 리뷰 데이터 분류 (긍정, 부정)보다 더 넓은 네트워크를 구축해야합니다. 왜냐하면 카테고리가 굉장히 많을 수 있기 때문입니다. 네트워크가 좁으면 각 카테고리에 대한 정보가 없어질 가능성이 있습니다. 학습이 시작되기 전, 각각의 뉴스 기사데이터는 형태소 분류와 POS taggin이 이루어져야 합니다. 그리고 모든 단어들에 대해 토큰화를 시켜주고 벡터화 해줍니다. (임베딩) 입력값은 뉴스 기사 데이터가 될 것이고, 출력값은 카테고리가 될 것이며 카테고리 개수에 맞는 크기의 벡터를 출력해야 합니다. 그렇기 때문에 마지막 activation function은 softmax을 사용하면 되고, loss function은 categorical cross_entropy을 사용하면 됩니다.
  * Softmax 함수는 출력값의 class 분류 (category 분류)를 위해 정규화를 해주는 함수입니다. 벡터 형태로 바꿔주며 모든 요소의 합은 항상 1입니다. 어느 한 벡터의 요소가 가장 크다면 그 input 값은 가장 큰 값을 가지고 있는 요소가 의미하는 카테고리라고 할 수 있습니다.
* Stop Words은 무엇일까요? 이것을 왜 제거해야 하나요?
* 영화 리뷰가 긍정적인지 부정적인지 예측하기 위해 모델을 어떻게 설계하시겠나요?
  * 먼저 리뷰 데이터가 필요합니다. 리뷰에 대한 긍정(1), 부정(0)의 label이 포함되어 있어야 합니다. 학습이 시작되기 전, 각각의 리뷰데이터는 형태소 분류와 POS tagging이 이루어져야 합니다. 그리고 모든 단어들에 대해 토큰화를 시켜주고 이를 벡터화 해줍니다. (임베딩) 한 리뷰에 대한 인스턴스가 layer를 통과하면 이에 대한 예측값(긍정, 부정)을 출력할 수 있도록 네트워크를 구성시킨 뒤에 학습을 시키면 됩니다. 데이터는 문장으로 되어 있어 sequence 데이터이기 때문에 모델은 RNN으로 설계해야 합니다. 특히 LSTM으로 구성하면 더 성능이 좋습니다.
* TF-IDF 점수는 무엇이며 어떤 경우 유용한가요?
* 한국어에서 많이 사용되는 사전은 무엇인가요?
* Regular grammar은 무엇인가요? Regular expression과 무슨 차이가 있나요?
* RNN에 대해 설명해주세요.
  * <https://jsstar522.github.io/machinelearning/2020/03/01/RNN(Recurrent-Neural-Network)에-대해서.html>
* LSTM은 왜 유용한가요?
* Translate 과정 Flow에 대해 설명해주세요
  * 가장 쉬운 방법으로는 단어마다 1대1로 번역단어를 대응시키면 되지만 이 방법은 문맥이나 언어마다 다른 문법을 고려하지 않을 수 있기 때문에 기계번역 기술을 사용하는 것이 유리합니다. 가장 대표적으로 `seq2seq 모델`이 있습니다. 
  * FLOW
    * 번역할 언어로 작성된 소스 문장을 토큰화 및 임베딩 하고 RNN 모델의 인풋으로 넣습니다.
    * 소스 문장의 가장 마지막 단어를 인풋으로 넣고 구한 RNN의 state을 타겟 문장(번역된 문장)의 첫번째 단어의 예측을 시작할 때 초기 state로 지정합니다.
    * `<s>` 은 문장의 시작을 의미하는 키워드로 번역할 언어로 작성된 타겟 문장의 첫번째 단어로 사용합니다.
    * `<s>` 을 넣고 RNN이 다음에 올 수 있는 타겟 단어 후보군을 softmax 행렬 형태로 예측하면 다음에 올 가장 그럴듯한 단어 (softmax 행렬 출력값 중 가장 큰 값을 가지는 단어)을 선택해서 `<s>` 다음 단어 (아래 예시에선 Je)로 확정합니다.
    * `<s>` 을 넣고 예측해서 구한 다음 단어 (Je)을 RNN의 인풋으로 넣고, 다시 다음에 올 수 있는 타겟 단어 후보군을 softmax 행렬 형태로 예측하면 다음에 올 가장 그럴 듯한 단어를 선택해서 다음단어 (아래 예시에선 suis)로 확정합니다.
    * 문장의 끝을 의미하는 `</s>` 가 나올 때까지 반복합니다.
    * <img src="https://raw.githubusercontent.com/jsstar522/jsstar522.github.io/master/static/img/_posts/20200908/4.jpg" alt="distribution" style="display:block; width:700px; margin: 0 auto;"/>
* 인공신경망 vs 통계기반 번역, 뭐가 다를까요?
  * https://zdnet.co.kr/view/?no=20161223190944
* n-gram은 무엇일까요?
  * <https://jsstar522.github.io/deeplearning/2020/09/06/word-embedding.html>
* PageRank 알고리즘은 어떻게 작동하나요?
* dependency parsing이란 무엇인가요?
* word2vec의 원리는 무엇인가요? (그림에서 왼쪽 파라미터들을 임베딩으로 쓰는 이유는? 오른쪽 파라미터의 의미는? 남자와 여자가 가까울까? 남자와 자동차가 가까울까? 번역을 unsupervised로 할 수 있을까?)
  * <https://jsstar522.github.io/deeplearning/2020/09/06/word-embedding.html>